{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a8a123-8383-4119-a768-9d64df9e5a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 40, 50, 60, 70]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_m = 10\n",
    "actual_c = 20\n",
    "\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [actual_m * i + actual_c for i in x]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6d8ebe-b276-42b2-b933-c78e41c6d1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean = sum(y)/len(y)\n",
    "y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bc1335-c5a8-41ae-baf7-a1691a72a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0 # random guess\n",
    "c = 0 # random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89cc1921-9798-4cf9-bbb9-91dc1038566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f33896-908b-4eb1-a550-f77641e7fdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(x)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2b81c8-1052-47b2-8528-f57a9f3f54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 0.01 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a3f738-3108-4b6c-a07b-289c44d0711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward():\n",
    "    return [m * i + c for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d954c1c0-95b6-43ef-b175-b05ea6772320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred):\n",
    "    return (1 / N) * sum( (y[i] - y_pred[i]) ** 2 for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b5e3d7-c350-4c03-af6e-992069c5e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_pred):\n",
    "    rss = sum( (y[i] - y_pred[i])**2 for i in range(N) )\n",
    "    tss = sum( (y[i] - y_mean)**2 for i in range(N) )\n",
    "    r2 = 1 - rss/tss \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a30e44-59eb-48cd-9a72-9615bca30739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_m(y_pred):\n",
    "    return (-2 / N) * sum( ( x[i] * (y[i] - y_pred[i]) ) for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b37611-1c95-43ed-9cc2-194ec44462c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_c(y_pred):\n",
    "    return (-2 / N) * sum( (y[i] - y_pred[i]) for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201a1e83-d7aa-4255-a6cd-0161a7f93391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.75964934783735 | Accuracy: 0.7962017532608132\n",
      "gradient of m: -0.14202371531931987 | graident of c: -5.483276691358663\n",
      "m: 14.07837182684236 | c: 5.082339652166752\n",
      "\n",
      "Loss: 40.462280481073634 | Accuracy: 0.7976885975946318\n",
      "gradient of m: 0.21821810353243906 | graident of c: -5.365089734612333\n",
      "m: 14.076189645807036 | c: 5.135990549512875\n",
      "\n",
      "Loss: 40.17619075507866 | Accuracy: 0.7991190462246067\n",
      "gradient of m: 0.4921155048320344 | graident of c: -5.270881026132037\n",
      "m: 14.071268490758715 | c: 5.188699359774195\n",
      "\n",
      "Loss: 39.897435395211296 | Accuracy: 0.8005128230239436\n",
      "gradient of m: 0.7001029553369051 | graident of c: -5.194990335899317\n",
      "m: 14.064267461205347 | c: 5.2406492631331885\n",
      "\n",
      "Loss: 39.62371044199938 | Accuracy: 0.8018814477900031\n",
      "gradient of m: 0.8577797253167617 | graident of c: -5.133096706501544\n",
      "m: 14.05568966395218 | c: 5.291980230198204\n",
      "\n",
      "Loss: 39.353668156517685 | Accuracy: 0.8032316592174116\n",
      "gradient of m: 0.977053988137186 | graident of c: -5.081901555890511\n",
      "m: 14.045919124070808 | c: 5.342799245757109\n",
      "\n",
      "Loss: 39.08651807230091 | Accuracy: 0.8045674096384955\n",
      "gradient of m: 1.067016204100439 | graident of c: -5.0388867640609325\n",
      "m: 14.035248962029804 | c: 5.393188113397718\n",
      "\n",
      "Loss: 38.821794507915655 | Accuracy: 0.8058910274604217\n",
      "gradient of m: 1.1346058450420173 | graident of c: -5.0021300010257335\n",
      "m: 14.023902903579383 | c: 5.443209413407976\n",
      "\n",
      "Loss: 38.55922108456657 | Accuracy: 0.8072038945771671\n",
      "gradient of m: 1.1851203591942863 | graident of c: -4.970163751707748\n",
      "m: 14.01205169998744 | c: 5.492911050925053\n",
      "\n",
      "Loss: 38.29863177343477 | Accuracy: 0.8085068411328262\n",
      "gradient of m: 1.222603705274024 | graident of c: -4.9418676982252485\n",
      "m: 13.9998256629347 | c: 5.542329727907306\n",
      "\n",
      "Loss: 38.03992488574716 | Accuracy: 0.8098003755712642\n",
      "gradient of m: 1.2501429520072407 | graident of c: -4.916386566577185\n",
      "m: 13.987324233414627 | c: 5.591493593573078\n",
      "\n",
      "Loss: 37.78303626024081 | Accuracy: 0.811084818698796\n",
      "gradient of m: 1.2700946965602768 | graident of c: -4.8930674123660785\n",
      "m: 13.974623286449024 | c: 5.640424267696738\n",
      "\n",
      "Loss: 37.52792363791899 | Accuracy: 0.812360381810405\n",
      "gradient of m: 1.2842579080589758 | graident of c: -4.871411745912377\n",
      "m: 13.961780707368433 | c: 5.689138385155862\n",
      "\n",
      "Loss: 37.27455755620951 | Accuracy: 0.8136272122189525\n",
      "gradient of m: 1.2940058730407018 | graident of c: -4.851038985477676\n",
      "m: 13.948840648638026 | c: 5.737648775010639\n",
      "\n",
      "Loss: 37.022916042309376 | Accuracy: 0.8148854197884532\n",
      "gradient of m: 1.300386920100408 | graident of c: -4.831658558150565\n",
      "m: 13.935836779437022 | c: 5.785965360592145\n",
      "\n",
      "Loss: 36.772981520507784 | Accuracy: 0.8161350923974611\n",
      "gradient of m: 1.3042013111673427 | graident of c: -4.813048602193582\n",
      "m: 13.922794766325348 | c: 5.834095846614081\n",
      "\n",
      "Loss: 36.52473900970862 | Accuracy: 0.8173763049514569\n",
      "gradient of m: 1.306059938842131 | graident of c: -4.795039708819752\n",
      "m: 13.909734166936927 | c: 5.882046243702278\n",
      "\n",
      "Loss: 36.27817507281839 | Accuracy: 0.8186091246359081\n",
      "gradient of m: 1.3064291348260413 | graident of c: -4.7775025109738865\n",
      "m: 13.896669875588666 | c: 5.929821268812017\n",
      "\n",
      "Loss: 36.033277204285326 | Accuracy: 0.8198336139785734\n",
      "gradient of m: 1.3056648758227511 | graident of c: -4.7603382088439705\n",
      "m: 13.883613226830438 | c: 5.977424650900456\n",
      "\n",
      "Loss: 35.790033472973185 | Accuracy: 0.8210498326351341\n",
      "gradient of m: 1.3040388956723747 | graident of c: -4.74347133721646\n",
      "m: 13.870572837873715 | c: 6.024859364272621\n",
      "\n",
      "Loss: 35.5484323138327 | Accuracy: 0.8222578384308366\n",
      "gradient of m: 1.3017586188574357 | graident of c: -4.726844244212474\n",
      "m: 13.85755525168514 | c: 6.072127806714746\n",
      "\n",
      "Loss: 35.30846240628648 | Accuracy: 0.8234576879685676\n",
      "gradient of m: 1.2989823773615414 | graident of c: -4.710412876459673\n",
      "m: 13.844565427911524 | c: 6.119231935479342\n",
      "\n",
      "Loss: 35.07011260314742 | Accuracy: 0.824649436984263\n",
      "gradient of m: 1.2958310269295994 | graident of c: -4.694143561572168\n",
      "m: 13.831607117642228 | c: 6.166173371095064\n",
      "\n",
      "Loss: 34.833371888987266 | Accuracy: 0.8258331405550636\n",
      "gradient of m: 1.2923968146994014 | graident of c: -4.678010551956504\n",
      "m: 13.818683149495234 | c: 6.212953476614628\n",
      "\n",
      "Loss: 34.59822935566852 | Accuracy: 0.8270088532216574\n",
      "gradient of m: 1.288750148582922 | graident of c: -4.66199414979934\n",
      "m: 13.805795648009404 | c: 6.2595734181126215\n",
      "\n",
      "Loss: 34.36467418787951 | Accuracy: 0.8281766290606025\n",
      "gradient of m: 1.2849447648826329 | graident of c: -4.64607927571833\n",
      "m: 13.792946200360579 | c: 6.306034210869805\n",
      "\n",
      "Loss: 34.13269565450067 | Accuracy: 0.8293365217274966\n",
      "gradient of m: 1.2810216731515611 | graident of c: -4.630254376096919\n",
      "m: 13.780135983629062 | c: 6.352336754630774\n",
      "\n",
      "Loss: 33.90228310336991 | Accuracy: 0.8304885844831504\n",
      "gradient of m: 1.2770121676240167 | graident of c: -4.614510588964078\n",
      "m: 13.767365861952822 | c: 6.398481860520415\n",
      "\n",
      "Loss: 33.673425958030336 | Accuracy: 0.8316328702098483\n",
      "gradient of m: 1.272940126084575 | graident of c: -4.598841107242239\n",
      "m: 13.754636460691977 | c: 6.444470271592838\n",
      "\n",
      "Loss: 33.44611371563443 | Accuracy: 0.8327694314218279\n",
      "gradient of m: 1.2688237647805167 | graident of c: -4.583240692662464\n",
      "m: 13.741948223044172 | c: 6.490302678519463\n",
      "\n",
      "Loss: 33.22033594552396 | Accuracy: 0.8338983202723802\n",
      "gradient of m: 1.264676978088555 | graident of c: -4.567705304696044\n",
      "m: 13.729301453263286 | c: 6.535979731566423\n",
      "\n",
      "Loss: 32.996082288204356 | Accuracy: 0.8350195885589782\n",
      "gradient of m: 1.2605103611908364 | graident of c: -4.552231817287438\n",
      "m: 13.716696349651377 | c: 6.5815020497392975\n",
      "\n",
      "Loss: 32.773342454550644 | Accuracy: 0.8361332877272468\n",
      "gradient of m: 1.256331990766087 | graident of c: -4.536817802613142\n",
      "m: 13.704133029743716 | c: 6.626870227765429\n",
      "\n",
      "Loss: 32.55210622514983 | Accuracy: 0.8372394688742508\n",
      "gradient of m: 1.2521480209543085 | graident of c: -4.521461366006849\n",
      "m: 13.691611549534173 | c: 6.672084841425497\n",
      "\n",
      "Loss: 32.33236344972382 | Accuracy: 0.838338182751381\n",
      "gradient of m: 1.2479631383047847 | graident of c: -4.50616101994397\n",
      "m: 13.679131918151125 | c: 6.717146451624937\n",
      "\n",
      "Loss: 32.11410404660043 | Accuracy: 0.8394294797669979\n",
      "gradient of m: 1.2437809090743714 | graident of c: -4.490915587843378\n",
      "m: 13.666694109060382 | c: 6.76205560750337\n",
      "\n",
      "Loss: 31.89731800221431 | Accuracy: 0.8405134099889284\n",
      "gradient of m: 1.2396040443486158 | graident of c: -4.475724130630971\n",
      "m: 13.654298068616896 | c: 6.80681284880968\n",
      "\n",
      "Loss: 31.6819953706261 | Accuracy: 0.8415900231468695\n",
      "gradient of m: 1.2354346024297926 | graident of c: -4.460585890679265\n",
      "m: 13.641943722592599 | c: 6.851418707716473\n",
      "\n",
      "Loss: 31.46812627305352 | Accuracy: 0.8426593686347323\n",
      "gradient of m: 1.231274143335989 | graident of c: -4.445500249011468\n",
      "m: 13.629630981159238 | c: 6.895873710206588\n",
      "\n",
      "Loss: 31.255700897411 | Accuracy: 0.8437214955129451\n",
      "gradient of m: 1.2271238467427565 | graident of c: -4.4304666926313985\n",
      "m: 13.61735974269181 | c: 6.940178377132901\n",
      "\n",
      "Loss: 31.044709497855138 | Accuracy: 0.8447764525107243\n",
      "gradient of m: 1.2229846020172204 | graident of c: -4.415484789583338\n",
      "m: 13.605129896671638 | c: 6.984333225028735\n",
      "\n",
      "Loss: 30.83514239433534 | Accuracy: 0.8458242880283233\n",
      "gradient of m: 1.2188570769484486 | graident of c: -4.400554169912702\n",
      "m: 13.592941325902153 | c: 7.028338766727861\n",
      "\n",
      "Loss: 30.626989972147857 | Accuracy: 0.8468650501392607\n",
      "gradient of m: 1.2147417702145447 | graident of c: -4.385674511131356\n",
      "m: 13.580793908200008 | c: 7.072195511839175\n",
      "\n",
      "Loss: 30.420242681494287 | Accuracy: 0.8478987865925286\n",
      "gradient of m: 1.2106390514352086 | graident of c: -4.370845527121605\n",
      "m: 13.568687517685655 | c: 7.115903967110391\n",
      "\n",
      "Loss: 30.214891037042676 | Accuracy: 0.8489255448147867\n",
      "gradient of m: 1.2065491917467428 | graident of c: -4.356066959665291\n",
      "m: 13.556622025768187 | c: 7.159464636707044\n",
      "\n",
      "Loss: 30.010925617492163 | Accuracy: 0.8499453719125392\n",
      "gradient of m: 1.2024723871423633 | graident of c: -4.341338571976793\n",
      "m: 13.544597301896763 | c: 7.2028780224268125\n",
      "\n",
      "Loss: 29.808337065140506 | Accuracy: 0.8509583146742975\n",
      "gradient of m: 1.1984087762896707 | graident of c: -4.326660143765795\n",
      "m: 13.532613214133866 | c: 7.2461446238644704\n",
      "\n",
      "Loss: 29.60711608545468 | Accuracy: 0.8519644195727266\n",
      "gradient of m: 1.1943584541318644 | graident of c: -4.312031467467867\n",
      "m: 13.520669629592547 | c: 7.289264938539149\n",
      "\n",
      "Loss: 29.407253446644486 | Accuracy: 0.8529637327667776\n",
      "gradient of m: 1.1903214822709174 | graident of c: -4.297452345366423\n",
      "m: 13.508766414769838 | c: 7.332239461992813\n",
      "\n",
      "Loss: 29.208739979238874 | Accuracy: 0.8539563001038056\n",
      "gradient of m: 1.1862978968933078 | graident of c: -4.282922587395348\n",
      "m: 13.496903435800904 | c: 7.375068687866767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    y_pred = forward()\n",
    "    loss = loss_fn(y_pred)\n",
    "    accuracy = r2_score(y_pred)\n",
    "    print(\"Loss:\", loss, \"| Accuracy:\", accuracy)\n",
    "\n",
    "    grad_m = gradient_m(y_pred)\n",
    "    grad_c = gradient_c(y_pred)\n",
    "    print(\"gradient of m:\", grad_m, \"| graident of c:\", grad_c)\n",
    "\n",
    "    m = m - L * grad_m\n",
    "    c = c - L * grad_c\n",
    "    print(\"m:\", m, \"| c:\", c)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d4bab-aeaf-4fbb-87bc-fac513ab7a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
