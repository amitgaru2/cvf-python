{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a8a123-8383-4119-a768-9d64df9e5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_m = 10\n",
    "actual_c = 20\n",
    "\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [actual_m * i + actual_c for i in x]\n",
    "y\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "y = [2, 1, 2, 1, 7, 6, 7, 6, 12, 11, 12, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6d8ebe-b276-42b2-b933-c78e41c6d1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean = sum(y)/len(y)\n",
    "y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bc1335-c5a8-41ae-baf7-a1691a72a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0 # random guess\n",
    "c = 0 # random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89cc1921-9798-4cf9-bbb9-91dc1038566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f33896-908b-4eb1-a550-f77641e7fdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(x)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2b81c8-1052-47b2-8528-f57a9f3f54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 0.01 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a3f738-3108-4b6c-a07b-289c44d0711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward():\n",
    "    return [m * i + c for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d954c1c0-95b6-43ef-b175-b05ea6772320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred):\n",
    "    return (1 / N) * sum( (y[i] - y_pred[i]) ** 2 for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b5e3d7-c350-4c03-af6e-992069c5e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_pred):\n",
    "    rss = sum( (y[i] - y_pred[i])**2 for i in range(N) )\n",
    "    tss = sum( (y[i] - y_mean)**2 for i in range(N) )\n",
    "    r2 = 1 - rss/tss \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a30e44-59eb-48cd-9a72-9615bca30739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_m(y_pred):\n",
    "    return (-2 / N) * sum( ( x[i] * (y[i] - y_pred[i]) ) for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b37611-1c95-43ed-9cc2-194ec44462c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_c(y_pred):\n",
    "    return (-2 / N) * sum( (y[i] - y_pred[i]) for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201a1e83-d7aa-4255-a6cd-0161a7f93391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 59.166666666666664 | Accuracy: -2.497536945812808\n",
      "gradient of m: -110.66666666666666 | graident of c: -13.0\n",
      "m: 1.1066666666666667 | c: 0.13\n",
      "\n",
      "Loss: 3.2312407407407417 | Accuracy: 0.8089906951286261\n",
      "gradient of m: 10.912222222222233 | graident of c: 1.6466666666666676\n",
      "m: 0.9975444444444443 | c: 0.11353333333333332\n",
      "\n",
      "Loss: 2.6819884894032926 | Accuracy: 0.8414588085081798\n",
      "gradient of m: -1.123418518518532 | graident of c: 0.19514444444444293\n",
      "m: 1.0087786296296297 | c: 0.1115818888888889\n",
      "\n",
      "Loss: 2.6755420027637364 | Accuracy: 0.8418398816100254\n",
      "gradient of m: 0.06824943209877461 | graident of c: 0.3372859629629641\n",
      "m: 1.008096135308642 | c: 0.10820902925925925\n",
      "\n",
      "Loss: 2.6744243370879213 | Accuracy: 0.8419059505169701\n",
      "gradient of m: -0.0495346278600867 | graident of c: 0.3216678175308638\n",
      "m: 1.0085914815872428 | c: 0.10499235108395061\n",
      "\n",
      "Loss: 2.67336802242334 | Accuracy: 0.8419683927631523\n",
      "gradient of m: -0.03768893062401316 | graident of c: 0.32167396280205673\n",
      "m: 1.008968370893483 | c: 0.10177561145593005\n",
      "\n",
      "Loss: 2.6723213574207563 | Accuracy: 0.8420302645859652\n",
      "gradient of m: -0.038676870945600794 | graident of c: 0.3201400445271372\n",
      "m: 1.009355139602939 | c: 0.09857421101065868\n",
      "\n",
      "Loss: 2.671283757074806 | Accuracy: 0.8420916005670065\n",
      "gradient of m: -0.03839513320971381 | graident of c: 0.31876523685952424\n",
      "m: 1.009739090935036 | c: 0.09538655864206344\n",
      "\n",
      "Loss: 2.6702551380092783 | Accuracy: 0.8421524056349194\n",
      "gradient of m: -0.03823988635759371 | graident of c: 0.3173812994395966\n",
      "m: 1.010121489798612 | c: 0.09221274564766747\n",
      "\n",
      "Loss: 2.6692354224360937 | Accuracy: 0.8422126843880142\n",
      "gradient of m: -0.03807291173069301 | graident of c: 0.31600485867729033\n",
      "m: 1.010502218915919 | c: 0.08905269706089457\n",
      "\n",
      "Loss: 2.6682245332881855 | Accuracy: 0.8422724413819792\n",
      "gradient of m: -0.03790788898381262 | graident of c: 0.3146342400287361\n",
      "m: 1.010881297805757 | c: 0.08590635466060721\n",
      "\n",
      "Loss: 2.6672223941660236 | Accuracy: 0.8423316811330429\n",
      "gradient of m: -0.03774346045508551 | graident of c: 0.31326958079605677\n",
      "m: 1.011258732410308 | c: 0.08277365885264665\n",
      "\n",
      "Loss: 2.666228929331383 | Accuracy: 0.8423904081183419\n",
      "gradient of m: -0.03757975713223283 | graident of c: 0.31191083903929656\n",
      "m: 1.0116345299816303 | c: 0.07965455046225368\n",
      "\n",
      "Loss: 2.6652440637016115 | Accuracy: 0.8424486267762594\n",
      "gradient of m: -0.03741676264742062 | graident of c: 0.3105579906857012\n",
      "m: 1.0120086976081044 | c: 0.07654897055539667\n",
      "\n",
      "Loss: 2.664267722843953 | Accuracy: 0.8425063415067614\n",
      "gradient of m: -0.03725447523519687 | graident of c: 0.3092110100161509\n",
      "m: 1.0123812423604563 | c: 0.07345686045523515\n",
      "\n",
      "Loss: 2.6632998329699253 | Accuracy: 0.8425635566717286\n",
      "gradient of m: -0.03709289169917843 | graident of c: 0.3078698715964022\n",
      "m: 1.012752171277448 | c: 0.07037816173927113\n",
      "\n",
      "Loss: 2.6623403209297454 | Accuracy: 0.8426202765952859\n",
      "gradient of m: -0.03693200899926981 | graident of c: 0.3065345500853669\n",
      "m: 1.013121491367441 | c: 0.06731281623841745\n",
      "\n",
      "Loss: 2.661389114206794 | Accuracy: 0.8426765055641303\n",
      "gradient of m: -0.03677182409448217 | graident of c: 0.305205020253566\n",
      "m: 1.0134892096083856 | c: 0.0642607660358818\n",
      "\n",
      "Loss: 2.6604461409121405 | Accuracy: 0.8427322478278537\n",
      "gradient of m: -0.03661233395843484 | graident of c: 0.30388125698077595\n",
      "m: 1.01385533294797 | c: 0.061221953466074036\n",
      "\n",
      "Loss: 2.659511329779109 | Accuracy: 0.8427875075992645\n",
      "gradient of m: -0.036453535577619545 | graident of c: 0.3025632352557581\n",
      "m: 1.0142198683037462 | c: 0.058196321113516455\n",
      "\n",
      "Loss: 2.6585846101578916 | Accuracy: 0.8428422890547059\n",
      "gradient of m: -0.036295425951774665 | graident of c: 0.30125093017573423\n",
      "m: 1.014582822563264 | c: 0.05518381181175911\n",
      "\n",
      "Loss: 2.6576659120102066 | Accuracy: 0.842896596334372\n",
      "gradient of m: -0.03613800209353061 | graident of c: 0.29994431694595025\n",
      "m: 1.0149442025841993 | c: 0.05218436864229961\n",
      "\n",
      "Loss: 2.6567551659040145 | Accuracy: 0.8429504335426199\n",
      "gradient of m: -0.0359812610285181 | graident of c: 0.29864337087918963\n",
      "m: 1.0153040151944845 | c: 0.049197934933507714\n",
      "\n",
      "Loss: 2.6558523030082553 | Accuracy: 0.8430038047482804\n",
      "gradient of m: -0.03582519979523842 | graident of c: 0.29734806739531483\n",
      "m: 1.015662267192437 | c: 0.046224454259554563\n",
      "\n",
      "Loss: 2.654957255087659 | Accuracy: 0.843056713984966\n",
      "gradient of m: -0.0356698154451216 | graident of c: 0.2960583820207894\n",
      "m: 1.016018965346888 | c: 0.043263870439346666\n",
      "\n",
      "Loss: 2.654069954497586 | Accuracy: 0.8431091652513742\n",
      "gradient of m: -0.03551510504228428 | graident of c: 0.29477429038823844\n",
      "m: 1.016374116397311 | c: 0.040316127535464284\n",
      "\n",
      "Loss: 2.65319033417891 | Accuracy: 0.8431611625115916\n",
      "gradient of m: -0.0353610656636113 | graident of c: 0.2934957682359711\n",
      "m: 1.0167277270539472 | c: 0.03738116985310457\n",
      "\n",
      "Loss: 2.6523183276529547 | Accuracy: 0.8432127096953919\n",
      "gradient of m: -0.03520769439869768 | graident of c: 0.29222279140752233\n",
      "m: 1.017079803997934 | c: 0.03445894193902935\n",
      "\n",
      "Loss: 2.6514538690164695 | Accuracy: 0.8432638106985338\n",
      "gradient of m: -0.035054988349762575 | graident of c: 0.29095533585120154\n",
      "m: 1.0174303538814318 | c: 0.03154938858051733\n",
      "\n",
      "Loss: 2.650596892936643 | Accuracy: 0.8433144693830557\n",
      "gradient of m: -0.03490294463150193 | graident of c: 0.2896933776196473\n",
      "m: 1.0177793833277469 | c: 0.02865245480432086\n",
      "\n",
      "Loss: 2.6497473346461744 | Accuracy: 0.843364689577566\n",
      "gradient of m: -0.03475156037124675 | graident of c: 0.2884368928693514\n",
      "m: 1.0181268989314594 | c: 0.025768085875627345\n",
      "\n",
      "Loss: 2.648905129938373 | Accuracy: 0.8434144750775345\n",
      "gradient of m: -0.034600832708743215 | graident of c: 0.2871858578602268\n",
      "m: 1.0184729072585468 | c: 0.022896227297025076\n",
      "\n",
      "Loss: 2.648070215162305 | Accuracy: 0.8434638296455781\n",
      "gradient of m: -0.03445075879610704 | graident of c: 0.2859402489551581\n",
      "m: 1.018817414846508 | c: 0.020036824807473496\n",
      "\n",
      "Loss: 2.6472425272179834 | Accuracy: 0.8435127570117448\n",
      "gradient of m: -0.03430133579782624 | graident of c: 0.2847000426195492\n",
      "m: 1.0191604282044862 | c: 0.017189824381278005\n",
      "\n",
      "Loss: 2.646422003551602 | Accuracy: 0.8435612608737969\n",
      "gradient of m: -0.03415256089071883 | graident of c: 0.28346521542087605\n",
      "m: 1.0195019538133934 | c: 0.014355172227069245\n",
      "\n",
      "Loss: 2.6456085821508086 | Accuracy: 0.8436093448974891\n",
      "gradient of m: -0.034004431263814985 | graident of c: 0.2822357440282525\n",
      "m: 1.0198419981260316 | c: 0.01153281478678672\n",
      "\n",
      "Loss: 2.6448022015400126 | Accuracy: 0.8436570127168466\n",
      "gradient of m: -0.03385694411835427 | graident of c: 0.2810116052119836\n",
      "m: 1.020180567567215 | c: 0.008722698734666884\n",
      "\n",
      "Loss: 2.6440028007757403 | Accuracy: 0.843704267934439\n",
      "gradient of m: -0.0337100966676956 | graident of c: 0.2797927758431299\n",
      "m: 1.0205176685338921 | c: 0.005924770976235585\n",
      "\n",
      "Loss: 2.6432103194420358 | Accuracy: 0.843751114121653\n",
      "gradient of m: -0.03356388613728356 | graident of c: 0.27857923289306963\n",
      "m: 1.020853307395265 | c: 0.0031389786473048882\n",
      "\n",
      "Loss: 2.642424697645885 | Accuracy: 0.8437975548189625\n",
      "gradient of m: -0.03341830976465232 | graident of c: 0.27737095343305584\n",
      "m: 1.0211874904929115 | c: 0.00036526911297432964\n",
      "\n",
      "Loss: 2.6416458760126993 | Accuracy: 0.8438435935361951\n",
      "gradient of m: -0.03327336479926124 | graident of c: 0.27616791463379736\n",
      "m: 1.021520224140904 | c: -0.002396410033363644\n",
      "\n",
      "Loss: 2.6408737956818182 | Accuracy: 0.8438892337527989\n",
      "gradient of m: -0.03312904850244987 | graident of c: 0.2749700937650258\n",
      "m: 1.0218515146259286 | c: -0.005146110971013902\n",
      "\n",
      "Loss: 2.6401083983020674 | Accuracy: 0.8439344789181044\n",
      "gradient of m: -0.032985358147575264 | graident of c: 0.2737774681950448\n",
      "m: 1.0221813682074044 | c: -0.00788388565296435\n",
      "\n",
      "Loss: 2.6393496260273484 | Accuracy: 0.8439793324515853\n",
      "gradient of m: -0.0328422910197282 | graident of c: 0.2725900153903283\n",
      "m: 1.0225097911176015 | c: -0.010609785806867632\n",
      "\n",
      "Loss: 2.6385974215122627 | Accuracy: 0.8440237977431175\n",
      "gradient of m: -0.03269984441577556 | graident of c: 0.2714077129150852\n",
      "m: 1.0228367895617594 | c: -0.013323862936018484\n",
      "\n",
      "Loss: 2.6378517279077824 | Accuracy: 0.8440678781532345\n",
      "gradient of m: -0.03255801564431178 | graident of c: 0.2702305384308346\n",
      "m: 1.0231623697182024 | c: -0.01602616832032683\n",
      "\n",
      "Loss: 2.6371124888569524 | Accuracy: 0.8441115770133821\n",
      "gradient of m: -0.032416802025654515 | graident of c: 0.2690584696959777\n",
      "m: 1.023486537738459 | c: -0.01871675301728661\n",
      "\n",
      "Loss: 2.6363796484906272 | Accuracy: 0.8441548976261698\n",
      "gradient of m: -0.03227620089167486 | graident of c: 0.267891484565393\n",
      "m: 1.0238092997473758 | c: -0.02139566786294054\n",
      "\n",
      "Loss: 2.6356531514232566 | Accuracy: 0.8441978432656203\n",
      "gradient of m: -0.03213620958584743 | graident of c: 0.2667295609900045\n",
      "m: 1.0241306618432342 | c: -0.024062963472840582\n",
      "\n",
      "Loss: 2.6349329427486907 | Accuracy: 0.8442404171774173\n",
      "gradient of m: -0.03199682546321843 | graident of c: 0.26557267701636383\n",
      "m: 1.0244506300978664 | c: -0.02671869024300422\n",
      "\n",
      "Loss: 2.6342189680360373 | Accuracy: 0.8442826225791504\n",
      "gradient of m: -0.031858045890193955 | graident of c: 0.26442081078625496\n",
      "m: 1.0247692105567683 | c: -0.02936289835086677\n",
      "\n",
      "Loss: 2.6335111733255445 | Accuracy: 0.8443244626605589\n",
      "gradient of m: -0.03171986824470322 | graident of c: 0.2632739405362542\n",
      "m: 1.0250864092392153 | c: -0.031995637756229316\n",
      "\n",
      "Loss: 2.6328095051245253 | Accuracy: 0.8443659405837719\n",
      "gradient of m: -0.031582289915980034 | graident of c: 0.2621320445973413\n",
      "m: 1.0254022321383751 | c: -0.03461695820220273\n",
      "\n",
      "Loss: 2.632113910403311 | Accuracy: 0.8444070594835481\n",
      "gradient of m: -0.031445308304668296 | graident of c: 0.2609951013944707\n",
      "m: 1.025716685221422 | c: -0.037226909216147436\n",
      "\n",
      "Loss: 2.6314243365912464 | Accuracy: 0.8444478224675125\n",
      "gradient of m: -0.03130892082254947 | graident of c: 0.2598630894461894\n",
      "m: 1.0260297744296474 | c: -0.03982554011060933\n",
      "\n",
      "Loss: 2.6307407315727165 | Accuracy: 0.8444882326163912\n",
      "gradient of m: -0.03117312489278745 | graident of c: 0.25873598736419745\n",
      "m: 1.0263415056785752 | c: -0.0424128999842513\n",
      "\n",
      "Loss: 2.630063043683206 | Accuracy: 0.8445282929842439\n",
      "gradient of m: -0.03103791794962163 | graident of c: 0.2576137738529749\n",
      "m: 1.0266518848580715 | c: -0.04498903772278105\n",
      "\n",
      "Loss: 2.629391221705397 | Accuracy: 0.8445680065986958\n",
      "gradient of m: -0.030903297438407584 | graident of c: 0.25649642770936754\n",
      "m: 1.0269609178324555 | c: -0.04755400199987473\n",
      "\n",
      "Loss: 2.6287252148652973 | Accuracy: 0.8446073764611647\n",
      "gradient of m: -0.030769260815686574 | graident of c: 0.25538392782217256\n",
      "m: 1.0272686104406124 | c: -0.050107841278096456\n",
      "\n",
      "Loss: 2.6280649728284016 | Accuracy: 0.8446464055470896\n",
      "gradient of m: -0.03063580554891554 | graident of c: 0.2542762531717676\n",
      "m: 1.0275749684961015 | c: -0.05265060380981413\n",
      "\n",
      "Loss: 2.6274104456958893 | Accuracy: 0.8446850968061543\n",
      "gradient of m: -0.030502929116588064 | graident of c: 0.25317338282969115\n",
      "m: 1.0278799977872675 | c: -0.05518233763811104\n",
      "\n",
      "Loss: 2.6267615840008514 | Accuracy: 0.8447234531625112\n",
      "gradient of m: -0.030370629008137435 | graident of c: 0.25207529595825473\n",
      "m: 1.028183704077349 | c: -0.05770309059769359\n",
      "\n",
      "Loss: 2.626118338704555 | Accuracy: 0.8447614775150016\n",
      "gradient of m: -0.0302389027238746 | graident of c: 0.2509819718101497\n",
      "m: 1.0284860931045876 | c: -0.060212910315795086\n",
      "\n",
      "Loss: 2.625480661192734 | Accuracy: 0.8447991727373754\n",
      "gradient of m: -0.030107747775003503 | graident of c: 0.24989338972804953\n",
      "m: 1.0287871705823377 | c: -0.06271184421307559\n",
      "\n",
      "Loss: 2.6248485032719175 | Accuracy: 0.8448365416785073\n",
      "gradient of m: -0.02997716168339411 | graident of c: 0.24880952914423932\n",
      "m: 1.0290869421991717 | c: -0.06519993950451798\n",
      "\n",
      "Loss: 2.6242218171657856 | Accuracy: 0.8448735871626136\n",
      "gradient of m: -0.029847141981800236 | graident of c: 0.24773036958019604\n",
      "m: 1.0293854136189897 | c: -0.06767724320031994\n",
      "\n",
      "Loss: 2.623600555511558 | Accuracy: 0.8449103119894645\n",
      "gradient of m: -0.02971768621360904 | graident of c: 0.24665589064622606\n",
      "m: 1.0296825904811258 | c: -0.0701438021067822\n",
      "\n",
      "Loss: 2.622984671356417 | Accuracy: 0.844946718934596\n",
      "gradient of m: -0.029588791932879922 | graident of c: 0.2455860720410702\n",
      "m: 1.0299784784004546 | c: -0.0725996628271929\n",
      "\n",
      "Loss: 2.622374118153959 | Accuracy: 0.8449828107495196\n",
      "gradient of m: -0.029460456704249495 | graident of c: 0.2445208935515252\n",
      "m: 1.030273082967497 | c: -0.07504487176270816\n",
      "\n",
      "Loss: 2.621768849760674 | Accuracy: 0.8450185901619306\n",
      "gradient of m: -0.029332678103023535 | graident of c: 0.2434603350520455\n",
      "m: 1.0305664097485274 | c: -0.07747947511322861\n",
      "\n",
      "Loss: 2.62116882043246 | Accuracy: 0.8450540598759136\n",
      "gradient of m: -0.02920545371484007 | graident of c: 0.2424043765043986\n",
      "m: 1.0308584642856757 | c: -0.0799035188782726\n",
      "\n",
      "Loss: 2.6205739848211644 | Accuracy: 0.8450892225721479\n",
      "gradient of m: -0.02907878113600141 | graident of c: 0.2413529979572397\n",
      "m: 1.0311492520970358 | c: -0.082317048857845\n",
      "\n",
      "Loss: 2.6199842979711607 | Accuracy: 0.8451240809081088\n",
      "gradient of m: -0.028952657973110973 | graident of c: 0.24030617954577496\n",
      "m: 1.031438778676767 | c: -0.08472011065330275\n",
      "\n",
      "Loss: 2.619399715315944 | Accuracy: 0.8451586375182694\n",
      "gradient of m: -0.028827081843181796 | graident of c: 0.23926390149136492\n",
      "m: 1.0317270494951987 | c: -0.0871127496682164\n",
      "\n",
      "Loss: 2.6188201926747716 | Accuracy: 0.8451928950142993\n",
      "gradient of m: -0.028702050373626237 | graident of c: 0.23822614410114962\n",
      "m: 1.0320140699989349 | c: -0.0894950111092279\n",
      "\n",
      "Loss: 2.618245686249316 | Accuracy: 0.8452268559852621\n",
      "gradient of m: -0.028577561202023705 | graident of c: 0.23719288776769698\n",
      "m: 1.0322998456109551 | c: -0.09186693998690487\n",
      "\n",
      "Loss: 2.6176761526203576 | Accuracy: 0.8452605229978114\n",
      "gradient of m: -0.028453611976297328 | graident of c: 0.23616411296860634\n",
      "m: 1.032584381730718 | c: -0.09422858111659094\n",
      "\n",
      "Loss: 2.617111548744506 | Accuracy: 0.8452938985963838\n",
      "gradient of m: -0.028330200354551877 | graident of c: 0.23513980026615378\n",
      "m: 1.0328676837342636 | c: -0.09657997911925248\n",
      "\n",
      "Loss: 2.6165518319509435 | Accuracy: 0.8453269853033925\n",
      "gradient of m: -0.028207324005049068 | graident of c: 0.2341199303069229\n",
      "m: 1.0331497569743142 | c: -0.0989211784223217\n",
      "\n",
      "Loss: 2.6159969599382 | Accuracy: 0.8453597856194167\n",
      "gradient of m: -0.028084980606138878 | graident of c: 0.2331044838214416\n",
      "m: 1.0334306067803756 | c: -0.10125222326053612\n",
      "\n",
      "Loss: 2.6154468907709605 | Accuracy: 0.8453923020233916\n",
      "gradient of m: -0.02796316784627787 | graident of c: 0.23209344162381076\n",
      "m: 1.0337102384588384 | c: -0.10357315767677423\n",
      "\n",
      "Loss: 2.6149015828768882 | Accuracy: 0.8454245369727947\n",
      "gradient of m: -0.027841883423910363 | graident of c: 0.23108678461134996\n",
      "m: 1.0339886572930774 | c: -0.10588402552288773\n",
      "\n",
      "Loss: 2.6143609950434907 | Accuracy: 0.8454564929038331\n",
      "gradient of m: -0.02772112504748958 | graident of c: 0.23008449376423074\n",
      "m: 1.0342658685435524 | c: -0.10818487046053003\n",
      "\n",
      "Loss: 2.6138250864150003 | Accuracy: 0.8454881722316256\n",
      "gradient of m: -0.02760089043537617 | graident of c: 0.22908655014512164\n",
      "m: 1.0345418774479063 | c: -0.11047573596198125\n",
      "\n",
      "Loss: 2.613293816489286 | Accuracy: 0.845519577350387\n",
      "gradient of m: -0.027481177315918554 | graident of c: 0.22809293489881824\n",
      "m: 1.0348166892210655 | c: -0.11275666531096944\n",
      "\n",
      "Loss: 2.6127671451147974 | Accuracy: 0.845550710633608\n",
      "gradient of m: -0.027361983427174847 | graident of c: 0.22710362925191263\n",
      "m: 1.0350903090553372 | c: -0.11502770160348856\n",
      "\n",
      "Loss: 2.612245032487521 | Accuracy: 0.8455815744342352\n",
      "gradient of m: -0.027243306517152156 | graident of c: 0.2261186145124066\n",
      "m: 1.0353627421205087 | c: -0.11728888774861262\n",
      "\n",
      "Loss: 2.611727439147985 | Accuracy: 0.8456121710848481\n",
      "gradient of m: -0.027125144343522013 | graident of c: 0.2251378720693878\n",
      "m: 1.035633993563944 | c: -0.1195402664693065\n",
      "\n",
      "Loss: 2.6112143259782643 | Accuracy: 0.8456425028978366\n",
      "gradient of m: -0.027007494673707777 | graident of c: 0.22416138339266\n",
      "m: 1.035904068510681 | c: -0.1217818803032331\n",
      "\n",
      "Loss: 2.6107056541990317 | Accuracy: 0.8456725721655745\n",
      "gradient of m: -0.0268903552849179 | graident of c: 0.2231891300323873\n",
      "m: 1.0361729720635302 | c: -0.12401377160355698\n",
      "\n",
      "Loss: 2.6102013853666257 | Accuracy: 0.8457023811605935\n",
      "gradient of m: -0.026773723963805764 | graident of c: 0.22222109361877843\n",
      "m: 1.0364407093031682 | c: -0.12623598253974477\n",
      "\n",
      "Loss: 2.609701481370143 | Accuracy: 0.845731932135755\n",
      "gradient of m: -0.026657598506793168 | graident of c: 0.2212572558616971\n",
      "m: 1.0367072852882362 | c: -0.12844855509836176\n",
      "\n",
      "Loss: 2.609205904428559 | Accuracy: 0.8457612273244202\n",
      "gradient of m: -0.02654197671979075 | graident of c: 0.22029759855034609\n",
      "m: 1.036972705055434 | c: -0.1306515310838652\n",
      "\n",
      "Loss: 2.608714617087875 | Accuracy: 0.8457902689406183\n",
      "gradient of m: -0.02642685641822551 | graident of c: 0.21934210355291217\n",
      "m: 1.0372369736196163 | c: -0.13284495211939432\n",
      "\n",
      "Loss: 2.6082275822182845 | Accuracy: 0.8458190591792147\n",
      "gradient of m: -0.02631223542701666 | graident of c: 0.21839075281622433\n",
      "m: 1.0375000959738865 | c: -0.13502885964755657\n",
      "\n",
      "Loss: 2.607744763011369 | Accuracy: 0.8458476002160766\n",
      "gradient of m: -0.026198111580536088 | graident of c: 0.21744352836541075\n",
      "m: 1.0377620770896918 | c: -0.13720329493121067\n",
      "\n",
      "Loss: 2.6072661229773133 | Accuracy: 0.8458758942082376\n",
      "gradient of m: -0.026084482722464587 | graident of c: 0.21650041230357175\n",
      "m: 1.0380229219169164 | c: -0.1393682990542464\n",
      "\n",
      "Loss: 2.6067916259421517 | Accuracy: 0.84590394329406\n",
      "gradient of m: -0.025971346705924603 | graident of c: 0.21556138681142048\n",
      "m: 1.0382826353839756 | c: -0.14152391292236058\n",
      "\n",
      "Loss: 2.6063212360450314 | Accuracy: 0.8459317495933971\n",
      "gradient of m: -0.025858701393335716 | graident of c: 0.21462643414696125\n",
      "m: 1.038541222397909 | c: -0.1436701772638302\n",
      "\n",
      "Loss: 2.6058549177355017 | Accuracy: 0.8459593152077536\n",
      "gradient of m: -0.02574654465633123 | graident of c: 0.21369553664515495\n",
      "m: 1.0387986878444722 | c: -0.14580713263028175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    y_pred = forward()\n",
    "    loss = loss_fn(y_pred)\n",
    "    accuracy = r2_score(y_pred)\n",
    "    print(\"Loss:\", loss, \"| Accuracy:\", accuracy)\n",
    "\n",
    "    grad_m = gradient_m(y_pred)\n",
    "    grad_c = gradient_c(y_pred)\n",
    "    print(\"gradient of m:\", grad_m, \"| graident of c:\", grad_c)\n",
    "\n",
    "    m = m - L * grad_m\n",
    "    c = c - L * grad_c\n",
    "    print(\"m:\", m, \"| c:\", c)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d4bab-aeaf-4fbb-87bc-fac513ab7a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
