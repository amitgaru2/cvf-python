{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04a8a123-8383-4119-a768-9d64df9e5a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 2, 1, 7, 6, 7, 6, 12, 11, 12, 11]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual_m = 10\n",
    "# actual_c = 20\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "y = [2, 1, 2, 1, 7, 6, 7, 6, 12, 11, 12, 11]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32096651-b8c2-41d9-9780-b07859bfe4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': [1, 2, 3, 4], 'y': [2, 1, 2, 1]},\n",
       " {'x': [5, 6, 7, 8], 'y': [7, 6, 7, 6]},\n",
       " {'x': [9, 10, 11, 12], 'y': [12, 11, 12, 11]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_1_data = {\"x\": x[:4], \"y\": y[:4]}\n",
    "node_2_data = {\"x\": x[4:8], \"y\": y[4:8]}\n",
    "node_3_data = {\"x\": x[8:12], \"y\": y[8:12]}\n",
    "\n",
    "node_data = [node_1_data, node_2_data, node_3_data]\n",
    "node_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b6d8ebe-b276-42b2-b933-c78e41c6d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = sum(y)/len(y)\n",
    "y_mean\n",
    "node_y_mean = [\n",
    "    sum(y[:4])/4,\n",
    "    sum(y[4:8])/4,\n",
    "    sum(y[8:12])/4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76bc1335-c5a8-41ae-baf7-a1691a72a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0 # random guess\n",
    "c = 0 # random guess\n",
    "node_params = [\n",
    "    {\"m\": 0, \"c\": 0},\n",
    "    {\"m\": 0, \"c\": 0},\n",
    "    {\"m\": 0, \"c\": 0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89cc1921-9798-4cf9-bbb9-91dc1038566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70f33896-908b-4eb1-a550-f77641e7fdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e2b81c8-1052-47b2-8528-f57a9f3f54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 0.05 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19a3f738-3108-4b6c-a07b-289c44d0711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_node(node_id):\n",
    "    params = node_params[node_id]\n",
    "    x = node_data[node_id][\"x\"]\n",
    "    return [params[\"m\"] * i + params[\"c\"] for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d954c1c0-95b6-43ef-b175-b05ea6772320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_node(node_id, y_pred):\n",
    "    y = node_data[node_id][\"y\"]\n",
    "    return (1 / N) * sum( (y[i] - y_pred[i]) ** 2 for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78b5e3d7-c350-4c03-af6e-992069c5e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_node(node_id, y_pred):\n",
    "    y = node_data[node_id][\"y\"]\n",
    "    y_mean = node_y_mean[node_id]\n",
    "    rss = sum( (y[i] - y_pred[i])**2 for i in range(N) )\n",
    "    tss = sum( (y[i] - y_mean)**2 for i in range(N) )\n",
    "    r2 = 1 - rss/tss \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3a30e44-59eb-48cd-9a72-9615bca30739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_m_node(node_id, y_pred):\n",
    "    x = node_data[node_id][\"x\"]\n",
    "    y = node_data[node_id][\"y\"]\n",
    "    return (-2 / N) * sum( ( x[i] * (y[i] - y_pred[i]) ) for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58b37611-1c95-43ed-9cc2-194ec44462c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_c_node(node_id, y_pred):\n",
    "    y = node_data[node_id][\"y\"]\n",
    "    return (-2 / N) * sum( (y[i] - y_pred[i]) for i in range(N) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201a1e83-d7aa-4255-a6cd-0161a7f93391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2700.0 | Accuracy: -12.5\n",
      "gradient of m: -340.0 | graident of c: -100.0\n",
      "m: 17.0 | c: 5.0\n",
      "\n",
      "Loss: 134.0 | Accuracy: 0.32999999999999996\n",
      "gradient of m: 64.0 | graident of c: 12.0\n",
      "m: 13.8 | c: 4.4\n",
      "\n",
      "Loss: 46.51999999999999 | Accuracy: 0.7674000000000001\n",
      "gradient of m: -9.99999999999998 | graident of c: -8.399999999999995\n",
      "m: 14.299999999999999 | c: 4.82\n",
      "\n",
      "Loss: 42.17839999999999 | Accuracy: 0.789108\n",
      "gradient of m: 3.519999999999979 | graident of c: -4.560000000000005\n",
      "m: 14.124 | c: 5.048000000000001\n",
      "\n",
      "Loss: 40.67115200000001 | Accuracy: 0.79664424\n",
      "gradient of m: 1.016000000000021 | graident of c: -5.159999999999996\n",
      "m: 14.0732 | c: 5.306000000000001\n",
      "\n",
      "Loss: 39.304571839999994 | Accuracy: 0.8034771408\n",
      "gradient of m: 1.4463999999999844 | graident of c: -4.948800000000005\n",
      "m: 14.00088 | c: 5.553440000000001\n",
      "\n",
      "Loss: 37.9868265152 | Accuracy: 0.810065867424\n",
      "gradient of m: 1.340000000000005 | graident of c: -4.887839999999999\n",
      "m: 13.93388 | c: 5.797832000000001\n",
      "\n",
      "Loss: 36.71335838758397 | Accuracy: 0.8164332080620802\n",
      "gradient of m: 1.3323519999999947 | graident of c: -4.801056\n",
      "m: 13.867262400000001 | c: 6.037884800000001\n",
      "\n",
      "Loss: 35.48258520849152 | Accuracy: 0.8225870739575424\n",
      "gradient of m: 1.307081600000032 | graident of c: -4.720655999999991\n",
      "m: 13.801908319999999 | c: 6.273917600000001\n",
      "\n",
      "Loss: 34.2930723967338 | Accuracy: 0.828534638016331\n",
      "gradient of m: 1.2854886399999943 | graident of c: -4.640714880000002\n",
      "m: 13.737633888 | c: 6.505953344000001\n",
      "\n",
      "Loss: 33.14343663597868 | Accuracy: 0.8342828168201066\n",
      "gradient of m: 1.2636655999999946 | graident of c: -4.562289984000002\n",
      "m: 13.674450607999999 | c: 6.734067843200001\n",
      "\n",
      "Loss: 32.03234109032448 | Accuracy: 0.8398382945483776\n",
      "gradient of m: 1.2423204351999588 | graident of c: -4.48516066560001\n",
      "m: 13.612334586240001 | c: 6.958325876480002\n",
      "\n",
      "Loss: 30.958493743318797 | Accuracy: 0.845207531283406\n",
      "gradient of m: 1.2213161561600445 | graident of c: -4.409340729599989\n",
      "m: 13.551268778431998 | c: 7.178792912960001\n",
      "\n",
      "Loss: 29.920645891992276 | Accuracy: 0.8503967705400386\n",
      "gradient of m: 1.2006706032639713 | graident of c: -4.334801503488008\n",
      "m: 13.491235248268799 | c: 7.395532988134402\n",
      "\n",
      "Loss: 28.91759069470875 | Accuracy: 0.8554120465264563\n",
      "gradient of m: 1.1803733907199956 | graident of c: -4.261522534118401\n",
      "m: 13.432216578732799 | c: 7.6086091148403225\n",
      "\n",
      "Loss: 27.9481617678082 | Accuracy: 0.860259191160959\n",
      "gradient of m: 1.160419421163512 | graident of c: -4.189482297922562\n",
      "m: 13.374195607674624 | c: 7.818083229736451\n",
      "\n",
      "Loss: 27.011231829299632 | Accuracy: 0.8649438408535018\n",
      "gradient of m: 1.140802747260429 | graident of c: -4.118659894479356\n",
      "m: 13.317155470311603 | c: 8.024016224460418\n",
      "\n",
      "Loss: 26.105711388022645 | Accuracy: 0.8694714430598868\n",
      "gradient of m: 1.1215176936177642 | graident of c: -4.049034729209549\n",
      "m: 13.261079585630714 | c: 8.226467960920896\n",
      "\n",
      "Loss: 25.230547476753333 | Accuracy: 0.8738472626162334\n",
      "gradient of m: 1.1025586494011008 | graident of c: -3.9805865643739198\n",
      "m: 13.205951653160659 | c: 8.425497289139592\n",
      "\n",
      "Loss: 24.384722427781387 | Accuracy: 0.8780763878610931\n",
      "gradient of m: 1.0839201043720295 | graident of c: -3.913295502756867\n",
      "m: 13.151755647942057 | c: 8.621162064277435\n",
      "\n",
      "Loss: 23.567252689534595 | Accuracy: 0.882163736552327\n",
      "gradient of m: 1.0655966403898744 | graident of c: -3.8471419837927856\n",
      "m: 13.098475815922564 | c: 8.813519163467074\n",
      "\n",
      "Loss: 22.777187682874466 | Accuracy: 0.8861140615856277\n",
      "gradient of m: 1.0475829310988531 | graident of c: -3.7821067775304673\n",
      "m: 13.046096669367621 | c: 9.002624502343597\n",
      "\n",
      "Loss: 22.013608695733538 | Accuracy: 0.8899319565213323\n",
      "gradient of m: 1.0298737401492233 | graident of c: -3.7181709791070845\n",
      "m: 12.99460298236016 | c: 9.18853305129895\n",
      "\n",
      "Loss: 21.27562781480842 | Accuracy: 0.8936218609259579\n",
      "gradient of m: 1.0124639197172087 | graident of c: -3.655316003241143\n",
      "m: 12.9439797863743 | c: 9.371298851461008\n",
      "\n",
      "Loss: 20.562386893066662 | Accuracy: 0.8971880655346667\n",
      "gradient of m: 0.995348409000627 | graident of c: -3.5935235788321904\n",
      "m: 12.894212365924268 | c: 9.550975030402617\n",
      "\n",
      "Loss: 19.87305655186684 | Accuracy: 0.9006347172406658\n",
      "gradient of m: 0.978522232749583 | graident of c: -3.5327757436491596\n",
      "m: 12.845286254286789 | c: 9.727613817585075\n",
      "\n",
      "Loss: 19.206835216531502 | Accuracy: 0.9039658239173425\n",
      "gradient of m: 0.9619804998197964 | graident of c: -3.4730548391091194\n",
      "m: 12.7971872292958 | c: 9.901266559540531\n",
      "\n",
      "Loss: 18.562948184251024 | Accuracy: 0.9071852590787449\n",
      "gradient of m: 0.9457184017507899 | graident of c: -3.4143435051441373\n",
      "m: 12.74990130920826 | c: 10.071983734797739\n",
      "\n",
      "Loss: 17.940646723235403 | Accuracy: 0.910296766383823\n",
      "gradient of m: 0.9297312113681656 | graident of c: -3.35662467515496\n",
      "m: 12.703414748639853 | c: 10.239814968555487\n",
      "\n",
      "Loss: 17.339207202065662 | Accuracy: 0.9133039639896717\n",
      "gradient of m: 0.9140142814096905 | graident of c: -3.2998815710499074\n",
      "m: 12.657714034569368 | c: 10.404809047107983\n",
      "\n",
      "Loss: 16.75793024823282 | Accuracy: 0.9162103487588359\n",
      "gradient of m: 0.8985630431739922 | graident of c: -3.244097698367826\n",
      "m: 12.612785882410668 | c: 10.567013932026375\n",
      "\n",
      "Loss: 16.1961399348859 | Accuracy: 0.9190193003255706\n",
      "gradient of m: 0.8833730051929379 | graident of c: -3.1892568414832443\n",
      "m: 12.568617232151022 | c: 10.726476774100538\n",
      "\n",
      "Loss: 15.653182994843148 | Accuracy: 0.9217340850257842\n",
      "gradient of m: 0.8684397519256977 | graident of c: -3.1353430588927953\n",
      "m: 12.525195244554737 | c: 10.883243927045179\n",
      "\n",
      "Loss: 15.128428060952864 | Accuracy: 0.9243578596952357\n",
      "gradient of m: 0.8537589424753094 | graident of c: -3.0823406785812155\n",
      "m: 12.482507297430972 | c: 11.03736096097424\n",
      "\n",
      "Loss: 14.621264931919928 | Accuracy: 0.9268936753404003\n",
      "gradient of m: 0.8393263093268133 | graident of c: -3.030234293465691\n",
      "m: 12.44054098196463 | c: 11.188872675647525\n",
      "\n",
      "Loss: 14.131103862745071 | Accuracy: 0.9293444806862746\n",
      "gradient of m: 0.8251376571070352 | graident of c: -2.979008756917165\n",
      "m: 12.399284099109279 | c: 11.337823113493384\n",
      "\n",
      "Loss: 13.657374878950847 | Accuracy: 0.9317131256052458\n",
      "gradient of m: 0.8111888613644297 | graident of c: -2.9286491783575617\n",
      "m: 12.358724656041057 | c: 11.484255572411262\n",
      "\n",
      "Loss: 13.199527113797899 | Accuracy: 0.9340023644310105\n",
      "gradient of m: 0.7974758673708124 | graident of c: -2.879140918931137\n",
      "m: 12.318850862672516 | c: 11.62821261835782\n",
      "\n",
      "Loss: 12.75702816771991 | Accuracy: 0.9362148591614005\n",
      "gradient of m: 0.7839946889422805 | graident of c: -2.8304695872492633\n",
      "m: 12.279651128225401 | c: 11.769736097720283\n",
      "\n",
      "Loss: 12.32936348923284 | Accuracy: 0.9383531825538358\n",
      "gradient of m: 0.7707414072805335 | graident of c: -2.7826210352070238\n",
      "m: 12.241114057861374 | c: 11.908867149480635\n",
      "\n",
      "Loss: 11.916035776598719 | Accuracy: 0.9404198211170064\n",
      "gradient of m: 0.7577121698340363 | graident of c: -2.7355813538704865\n",
      "m: 12.203228449369671 | c: 12.04564621717416\n",
      "\n",
      "Loss: 11.51656439954759 | Accuracy: 0.9424171780022621\n",
      "gradient of m: 0.7449031891777438 | graident of c: -2.6893368694336504\n",
      "m: 12.165983289910784 | c: 12.180113060645843\n",
      "\n",
      "Loss: 11.130484840385762 | Accuracy: 0.9443475757980712\n",
      "gradient of m: 0.7323107419123005 | graident of c: -2.6438741392436103\n",
      "m: 12.129367752815169 | c: 12.312306767608023\n",
      "\n",
      "Loss: 10.75734815384044 | Accuracy: 0.9462132592307978\n",
      "gradient of m: 0.7199311675818564 | graident of c: -2.599179947892941\n",
      "m: 12.093371194436076 | c: 12.44226576500267\n",
      "\n",
      "Loss: 10.396720445011923 | Accuracy: 0.9480163977749404\n",
      "gradient of m: 0.7077608676096645 | graident of c: -2.55524130337821\n",
      "m: 12.057983151055593 | c: 12.57002783017158\n",
      "\n",
      "Loss: 10.048182364827502 | Accuracy: 0.9497590881758625\n",
      "gradient of m: 0.6957963042525265 | graident of c: -2.512045433323282\n",
      "m: 12.023193335842967 | c: 12.695630101837745\n",
      "\n",
      "Loss: 9.711328622409123 | Accuracy: 0.9514433568879543\n",
      "gradient of m: 0.6840339995717472 | graident of c: -2.469579781266708\n",
      "m: 11.98899163586438 | c: 12.81910909090108\n",
      "\n",
      "Loss: 9.385767513788707 | Accuracy: 0.9530711624310565\n",
      "gradient of m: 0.6724705344228425 | graident of c: -2.4278320030115594\n",
      "m: 11.955368109143238 | c: 12.940500691051657\n",
      "\n",
      "Loss: 9.07112046642265 | Accuracy: 0.9546443976678868\n",
      "gradient of m: 0.6611025474612036 | graident of c: -2.3867899630372507\n",
      "m: 11.922312981770178 | c: 13.05984018920352\n",
      "\n",
      "Loss: 8.767021598975894 | Accuracy: 0.9561648920051206\n",
      "gradient of m: 0.6499267341650324 | graident of c: -2.346441730971893\n",
      "m: 11.889816645061925 | c: 13.177162275752114\n",
      "\n",
      "Loss: 8.473117295863814 | Accuracy: 0.9576344135206809\n",
      "gradient of m: 0.6389398458750577 | graident of c: -2.306775578124217\n",
      "m: 11.857869652768173 | c: 13.292501054658324\n",
      "\n",
      "Loss: 8.189065796056996 | Accuracy: 0.959054671019715\n",
      "gradient of m: 0.6281386888497593 | graident of c: -2.2677799740743128\n",
      "m: 11.826462718325685 | c: 13.40589005336204\n",
      "\n",
      "Loss: 7.914536795671004 | Accuracy: 0.960427316021645\n",
      "gradient of m: 0.6175201233372803 | graident of c: -2.2294435833218187\n",
      "m: 11.795586712158821 | c: 13.51736223252813\n",
      "\n",
      "Loss: 7.649211063878759 | Accuracy: 0.9617539446806062\n",
      "gradient of m: 0.6070810626628514 | graident of c: -2.1917552619908123\n",
      "m: 11.765232659025678 | c: 13.62694999562767\n",
      "\n",
      "Loss: 7.392780071699024 | Accuracy: 0.9630360996415048\n",
      "gradient of m: 0.5968184723309378 | graident of c: -2.154704054590593\n",
      "m: 11.73539173540913 | c: 13.7346851983572\n",
      "\n",
      "Loss: 7.144945633229354 | Accuracy: 0.9642752718338532\n",
      "gradient of m: 0.5867293691440807 | graident of c: -2.1182791908308163\n",
      "m: 11.706055266951926 | c: 13.84059915789874\n",
      "\n",
      "Loss: 6.9054195589063 | Accuracy: 0.9654729022054684\n",
      "gradient of m: 0.5768108203348191 | graident of c: -2.0824700824909628\n",
      "m: 11.677214725935185 | c: 13.944722662023288\n",
      "\n",
      "Loss: 6.673923320389668 | Accuracy: 0.9666303833980516\n",
      "gradient of m: 0.5670599427138001 | graident of c: -2.047266320342314\n",
      "m: 11.648861728799496 | c: 14.047085978040403\n",
      "\n",
      "Loss: 6.450187726681107 | Accuracy: 0.9677490613665944\n",
      "gradient of m: 0.5574739018313253 | graident of c: -2.01265767112222\n",
      "m: 11.62098803370793 | c: 14.147718861596514\n",
      "\n",
      "Loss: 6.233952611100476 | Accuracy: 0.9688302369444977\n",
      "gradient of m: 0.5480499111535281 | graident of c: -1.9786340745593962\n",
      "m: 11.593585538150252 | c: 14.246650565324485\n",
      "\n",
      "Loss: 6.024966528756003 | Accuracy: 0.96987516735622\n",
      "gradient of m: 0.5387852312524529 | graident of c: -1.9451856404495176\n",
      "m: 11.56664627658763 | c: 14.34390984734696\n",
      "\n",
      "Loss: 5.822986464156363 | Accuracy: 0.9708850676792182\n",
      "gradient of m: 0.5296771690096336 | graident of c: -1.912302645780298\n",
      "m: 11.540162418137148 | c: 14.439524979635976\n",
      "\n",
      "Loss: 5.627777548624652 | Accuracy: 0.9718611122568768\n",
      "gradient of m: 0.52072307683313 | graident of c: -1.8799755319051543\n",
      "m: 11.514126264295491 | c: 14.533523756231235\n",
      "\n",
      "Loss: 5.439112787185998 | Accuracy: 0.97280443606407\n",
      "gradient of m: 0.5119203518882216 | graident of c: -1.8481949017645833\n",
      "m: 11.48853024670108 | c: 14.625933501319464\n",
      "\n",
      "Loss: 5.256772794610555 | Accuracy: 0.9737161360269472\n",
      "gradient of m: 0.5032664353405508 | graident of c: -1.8169515171545911\n",
      "m: 11.463366924934052 | c: 14.716781077177194\n",
      "\n",
      "Loss: 5.0805455403057245 | Accuracy: 0.9745972722984714\n",
      "gradient of m: 0.4947588116123058 | graident of c: -1.786236296041301\n",
      "m: 11.438628984353436 | c: 14.806092891979258\n",
      "\n",
      "Loss: 4.910226101760338 | Accuracy: 0.9754488694911984\n",
      "gradient of m: 0.48639500765113014 | graident of c: -1.75604030992087\n",
      "m: 11.41430923397088 | c: 14.893894907475302\n",
      "\n",
      "Loss: 4.745616426254439 | Accuracy: 0.9762719178687278\n",
      "gradient of m: 0.4781725922111491 | graident of c: -1.726354781224123\n",
      "m: 11.390400604360321 | c: 14.980212646536508\n",
      "\n",
      "Loss: 4.586525100557404 | Accuracy: 0.9770673744972129\n",
      "gradient of m: 0.47008917514611714 | graident of c: -1.6971710807650568\n",
      "m: 11.366896145603016 | c: 15.06507120057476\n",
      "\n",
      "Loss: 4.432767128346756 | Accuracy: 0.9778361643582663\n",
      "gradient of m: 0.46214240671492635 | graident of c: -1.6684807252323794\n",
      "m: 11.34378902526727 | c: 15.148495236836379\n",
      "\n",
      "Loss: 4.284163715088699 | Accuracy: 0.9785791814245565\n",
      "gradient of m: 0.4543299768982351 | graident of c: -1.6402753747236163\n",
      "m: 11.321072526422359 | c: 15.230509005572559\n",
      "\n",
      "Loss: 4.14054206013026 | Accuracy: 0.9792972896993487\n",
      "gradient of m: 0.4466496147272409 | graident of c: -1.61254683032073\n",
      "m: 11.298740045685998 | c: 15.311136347088595\n",
      "\n",
      "Loss: 4.001735155761387 | Accuracy: 0.9799913242211931\n",
      "gradient of m: 0.43909908762351507 | graident of c: -1.585287031706824\n",
      "m: 11.276785091304822 | c: 15.390400698673936\n",
      "\n",
      "Loss: 3.86758159301318 | Accuracy: 0.9806620920349342\n",
      "gradient of m: 0.431676200749709 | graident of c: -1.5584880548231952\n",
      "m: 11.255201281267336 | c: 15.468325101415095\n",
      "\n",
      "Loss: 3.7379253739664975 | Accuracy: 0.9813103731301676\n",
      "gradient of m: 0.42437879637195697 | graident of c: -1.532142109565794\n",
      "m: 11.233982341448739 | c: 15.544932206893385\n",
      "\n",
      "Loss: 3.6126157303528745 | Accuracy: 0.9819369213482356\n",
      "gradient of m: 0.41720475323256495 | graident of c: -1.5062415375207963\n",
      "m: 11.21312210378711 | c: 15.620244283769425\n",
      "\n",
      "Loss: 3.4915069482363634 | Accuracy: 0.9825424652588182\n",
      "gradient of m: 0.41015198593298124 | graident of c: -1.4807788097384873\n",
      "m: 11.19261450449046 | c: 15.694283224256349\n",
      "\n",
      "Loss: 3.374458198572938 | Accuracy: 0.9831277090071353\n",
      "gradient of m: 0.40321844432824894 | graident of c: -1.4557465245445345\n",
      "m: 11.172453582274049 | c: 15.767070550483576\n",
      "\n",
      "Loss: 3.261333373450071 | Accuracy: 0.9836933331327496\n",
      "gradient of m: 0.39640211293052235 | graident of c: -1.4311374053885573\n",
      "m: 11.152633476627523 | c: 15.838627420753003\n",
      "\n",
      "Loss: 3.1520009278163053 | Accuracy: 0.9842399953609184\n",
      "gradient of m: 0.3897010103235175 | graident of c: -1.406944298728857\n",
      "m: 11.133148426111347 | c: 15.908974635689447\n",
      "\n",
      "Loss: 3.0463337265165262 | Accuracy: 0.9847683313674174\n",
      "gradient of m: 0.3831131885863215 | graident of c: -1.3831601719530227\n",
      "m: 11.113992766682031 | c: 15.978132644287097\n",
      "\n",
      "Loss: 2.944208896455278 | Accuracy: 0.9852789555177236\n",
      "gradient of m: 0.3766367327272903 | graident of c: -1.3597781113336127\n",
      "m: 11.095160930045667 | c: 16.046121549853776\n",
      "\n",
      "Loss: 2.84550768371614 | Accuracy: 0.9857724615814193\n",
      "gradient of m: 0.3702697601273144 | graident of c: -1.336791320018449\n",
      "m: 11.0766474420393 | c: 16.1129611158547\n",
      "\n",
      "Loss: 2.750115315470996 | Accuracy: 0.986249423422645\n",
      "gradient of m: 0.36401041999278905 | graident of c: -1.3141931160548042\n",
      "m: 11.05844692103966 | c: 16.17867077165744\n",
      "\n",
      "Loss: 2.657920866518589 | Accuracy: 0.986710395667407\n",
      "gradient of m: 0.35785689281715494 | graident of c: -1.2919769304471616\n",
      "m: 11.040554076398802 | c: 16.2432696181798\n",
      "\n",
      "Loss: 2.5688171302973273 | Accuracy: 0.9871559143485134\n",
      "gradient of m: 0.3518073898524279 | graident of c: -1.2701363052475927\n",
      "m: 11.02296370690618 | c: 16.306776433442177\n",
      "\n",
      "Loss: 2.482700494222129 | Accuracy: 0.9875864975288894\n",
      "gradient of m: 0.34586015258902025 | graident of c: -1.248664891678567\n",
      "m: 11.00567069927673 | c: 16.369209678026106\n",
      "\n",
      "Loss: 2.39947081920049 | Accuracy: 0.9880026459039976\n",
      "gradient of m: 0.3400134522446848 | graident of c: -1.2275564482874104\n",
      "m: 10.988670026664495 | c: 16.430587500440478\n",
      "\n",
      "Loss: 2.3190313231876902 | Accuracy: 0.9884048433840615\n",
      "gradient of m: 0.3342655892617472 | graident of c: -1.2068048391320758\n",
      "m: 10.971956747201409 | c: 16.49092774239708\n",
      "\n",
      "Loss: 2.241288468645604 | Accuracy: 0.988793557656772\n",
      "gradient of m: 0.32861489281346795 | graident of c: -1.1864040319973896\n",
      "m: 10.955526002560735 | c: 16.55024794399695\n",
      "\n",
      "Loss: 2.1661518537743154 | Accuracy: 0.9891692407311284\n",
      "gradient of m: 0.32305972031786184 | graident of c: -1.1663480966416913\n",
      "m: 10.939373016544842 | c: 16.608565348829035\n",
      "\n",
      "Loss: 2.093534107390203 | Accuracy: 0.989532329463049\n",
      "gradient of m: 0.31759845696073374 | graident of c: -1.1466312030728787\n",
      "m: 10.923493093696806 | c: 16.66589690898268\n",
      "\n",
      "Loss: 2.023350787327914 | Accuracy: 0.9898832460633604\n",
      "gradient of m: 0.3122295152258232 | graident of c: -1.1272476198538015\n",
      "m: 10.907881617935514 | c: 16.722259289975373\n",
      "\n",
      "Loss: 1.9555202822484707 | Accuracy: 0.9902223985887576\n",
      "gradient of m: 0.30695133443356326 | graident of c: -1.1081917124361667\n",
      "m: 10.892534051213836 | c: 16.777668875597183\n",
      "\n",
      "Loss: 1.8899637167390382 | Accuracy: 0.9905501814163048\n",
      "gradient of m: 0.3017623802874894 | graident of c: -1.0894579415226175\n",
      "m: 10.877445932199462 | c: 16.832141772673314\n",
      "\n",
      "Loss: 1.8266048595941944 | Accuracy: 0.990866975702029\n",
      "gradient of m: 0.29666114442807157 | graident of c: -1.071040861456595\n",
      "m: 10.862612874978058 | c: 16.885693815746144\n",
      "\n",
      "Loss: 1.7653700351718387 | Accuracy: 0.9911731498241408\n",
      "gradient of m: 0.29164614399413297 | graident of c: -1.052935118639364\n",
      "m: 10.848030567778352 | c: 16.93834057167811\n",
      "\n",
      "Loss: 1.706188037720994 | Accuracy: 0.991469059811395\n",
      "gradient of m: 0.2867159211924104 | graident of c: -1.0351354499736658\n",
      "m: 10.833694771718731 | c: 16.990097344176796\n",
      "\n",
      "Loss: 1.6489900485814228 | Accuracy: 0.9917550497570928\n",
      "gradient of m: 0.2818690428728445 | graident of c: -1.0176366813340252\n",
      "m: 10.819601319575089 | c: 17.040979178243497\n",
      "\n",
      "Loss: 1.593709556159266 | Accuracy: 0.9920314522192036\n",
      "gradient of m: 0.27710410011294045 | graident of c: -1.0004337260624723\n",
      "m: 10.805746114569441 | c: 17.09100086454662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    y_pred = forward()\n",
    "    loss = loss_fn(y_pred)\n",
    "    accuracy = r2_score(y_pred)\n",
    "    print(\"Loss:\", loss, \"| Accuracy:\", accuracy)\n",
    "\n",
    "    grad_m = gradient_m(y_pred)\n",
    "    grad_c = gradient_c(y_pred)\n",
    "    print(\"gradient of m:\", grad_m, \"| graident of c:\", grad_c)\n",
    "\n",
    "    m = m - L * grad_m\n",
    "    c = c - L * grad_c\n",
    "    print(\"m:\", m, \"| c:\", c)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d4bab-aeaf-4fbb-87bc-fac513ab7a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
